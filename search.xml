<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[MOT Metrics in Academia and Industry]]></title>
    <url>%2F2019%2F06%2F03%2FMOT-Metrics-in-Academia-and-Industry%2F</url>
    <content type="text"><![CDATA[MOT 是一个比较基本的技术模块，在视频监控中，常用于行人行为分析、姿态估计等任务的前序模块；在自动驾驶中，MOT 是动态目标状态估计的重要环节。在学术界，MOT 算法性能的评价准则已经较为完善，其指标主要关注，尽可能地覆盖所有性能维度，以及指标的简洁性（上一篇有较多介绍，the CLEAR MOT Metrics）。而工业界则尚无统一的标准，实际的指标需求情况也比学术界复杂。 指标的计算过程可由三部分组成，真值过滤(Filter)，匹配构建(Establishing Correspondences)与指标计算(Calculating Metrics)。其中真值过滤，更多的是工程细节，学术界没有文章对这一部分进行讨论研究。本文首先介绍学术界各评价指标详情，然后讨论工业界需要的评价指标又是怎样的。 1.&ensp;Metrics in Academia 在学术界，因为数据集质量较高，噪声相对较小，匹配构建中距离的度量偏向于严格且简单的方式。对于区域(框)跟踪器，采用重叠区域来度量；对于点跟踪器，采用中心点的欧式距离来度量。指标汇总如下：A.&ensp;检测指标 \(\lozenge\) 准确性(Accuracy) Recall = \(\frac{TP}{GT}\)； Precision = \(\frac{TP}{TP+FP}\)； FAF/FPPI[1][2] ，Average False Alarms per Frame；False Positive Per Image; MODA[3]，Multipe Object Detection Precision，整合了 FN 与 FP，设 \(c_m, c_f\) 分别为 FN，FP 的权重：$$MODA=1-\frac{\sum_{t=1}^{N_frames}(c_m(fn_t)+c_f(fp_t))}{\sum_{t=1}^{N_frames}gt_t}$$ \(\lozenge\) 精确性(Precision) MODP[3]，Multiple Object Detection Accuracy，$$MODP=\frac{\sum_{t=1}^{N_frames} \sum_{i=1}^{N_{mapped}^{(t)}} \;\; dist}{\sum_{t=1}^{N_frames} N_{mapped}^{(t)}}$$其中 \(N_{mapped}^{(t)}\) 为第 \(t\) 帧匹配的目标数；\(dist\) 为距离度量方法，如框的交并比度量法：$$Mapped Overlap Ratio = \frac{\lvert G_i^{(t)}\bigcap D_i^{(t)}\rvert}{|G_i^{(t)}\bigcup D_i^{(t)}|}$$ B.&ensp;跟踪指标 \(\lozenge\) 准确性(Accuracy) IDS[4]，ID switch，a tracked target changes its ID with another target(预测关联真值)； MOTA[5]，Multiple Object Tracking Accuracy，整合了 FN，FP，ID-Switch：$$MOTA=1-\frac{\sum_{t=1}^{N_{frames}} \;\; (c_m(fn_t)+c_f(fp_t)+c_s(ID-SWITCHES_t))}{\sum_{t=1}^{N_{frames}} \;\; gt_t}$$其中权重方程一般可设为：\(c_m=c_f=1, \quad c_s=log_{10}\)； \(\lozenge\) 精确性(Precision) MOTP[5]，Multiple Object Tracking Precision，$$MODP=\frac{\sum_{t=1}^{N_frames} \sum_{i=1}^{N_{mapped}^{(t)}} \;\; \left(\frac{\lvert G_i^{(t)}\bigcap D_i^{(t)}\rvert}{|G_i^{(t)}\bigcup D_i^{(t)}|} \right)}{\sum_{t=1}^{N_frames} N_{mapped}^{(t)}}$$ TDE[6]，Distance between the ground-truth annotation and the tracking result；像素级别的误差计算，适用于人群跟踪； OSPA[7][8]，Optimal Subpattern assignment，由定位 (localization) 误差及基数 (cardinality) 误差构成，对于第 \(t\) 帧：$$e^t=\left[\frac{1}{n^t}\left( \mathop{\min}_{\pi\in\Pi_n} \sum_{i=1}^{m^t} d^{(c)}(x_i^t,y_{\pi(i)}^t)^p + (n^t-m^t)\cdot c^p \right) \right]^{1/p}$$其中，\(n^t\) 为目标真值与算法输出中数量较大者。\(\Pi_n\) 为从 \(n^t\) 中取出的 \(m\) 个目标。\(p\) 为距离指数范数。其中定位截断误差为：$$d^{(c)}(x_i^t,y_{\pi(i)}^t) = \mathop{\min}\left(c,d(x_i^t,y_{\pi(i)}^t)\right)$$\(c\) 为截断参数。定位误差又由距离误差和标签误差组成：$$d(x_i^t,y_{\pi(i)}^t=\parallel x_i^t-y_{\pi(i)}^t\parallel + \alpha \; \bar{\delta}(l_x, l_y)$$其中 \(\alpha\in[0,c]\)，为标签误差的权重系数。如果 \(l_x=l_y\)，\(\bar{\delta}(l_x, l_y)=0\)，否则 \(\bar{\delta}(l_x, l_y)=1\). \(\lozenge\) 完整性(Completeness) MT[9]，Mostly Tracked，真值轨迹长度被跟踪大于80%的比例； ML[9]，Mostly Lost，真值轨迹长度被跟踪小于20%的比例； PT[9]，Partially Tracked，\(1-MT-ML\); FM[9]，Fragments，ID of a target changed along a GT trajectory, or no ID(真值关联预测)； \(\lozenge\) 鲁棒性(Robustne) RS[10]，Recover from short term occlusion; RL[10]，Recover from long term occlusion; 2.&ensp;Metrics in Industry 工业界的数据噪声较大，传感器配置也比较多样，不同的产品（传感器+算法），对 MOT 性能维度要求也不一样。更重要的是，评价指标应该从功能层面进行定义，在模块层面 (MOT) 进行调整及细化。可以说，工业界是以学术界为基础来设计 MOT 指标的，不同的产品没有统一的标准，但有比较通用的设计准则。 这里以自动驾驶/辅助驾驶中动态目标状态估计模块为例，模块详细分析日后再写。该模块的基本输入为： 传感器数据，可以是图像，激光等； 自定位系统，可以是基于视觉的 VO，基于视觉-IMU 的 VINS等；其中自定位系统能使目标状态估计在世界坐标系（惯性系）下优化，否则只能在本体（ego）非惯性系下优化，会减少一些约束量。该功能的基本输出为： 位置，本体坐标系下目标的三维位置，\(x,y,z\)； 尺寸，目标的物理尺寸大小，包括立方体的长宽高；或者图像坐标系下的像素大小；或者图像/点云下目标的 mask，即分割后的目标； 朝向，一般只考虑目标的航向角； 速度，本体坐标系或世界坐标系下的三维速度，一般只考虑航向平面的速度； 其中朝向是非必须项，有了朝向后，能更有效地进行状态优化。该模块的子模块有（注意，MOT 只包含前三者）： 检测(Detection)，进行多目标检测； 跟踪(Tracking)，根据上一帧结果，进行多目标跟踪； 数据关联(Association)，检测结果与跟踪结果的融合，出目标的 tracklets，生成 ID； 状态估计(State Estimation)，不同的方法包括不同的部分； 工业界设计产品时，基本遵循自顶向下的策略：产品需求-功能需求-模块需求，层层推倒。所以我们设计评价准则时，一般会问几个问题： 该模块服务的产品功能，其需求及对应的指标是什么？ 要达到功能指标，本模块的输出需要哪些指标来评测？ 各个子模块对模块的影响是怎样的，对应需要增加哪些指标？ 这里提到了功能指标，模块指标，子模块指标三层概念。功能指标及部分模块指标是可以写入产品手册的，所以需要突出重点，易于理解；部分模块及子模块指标则主要是为了产品上工程优化迭代，这就要求这部分指标要相当细致，将模块的不足尽可能解耦，且完全暴露出来。以下通过两个例子来分析设计过程。 2.1.&ensp;ADAS 中的 FCW 功能 FCW 基本功能要求为： 不允许误报，尽可能不漏报； 在 V km/h 下，以一定的刹车加速度 a，能避免与静止的前车相碰撞； 由以上两个功能需求，可确定必须的功能指标： （百公里）误报率； （百公里）漏报率； 观测距离，可由第二项功能要求推到出（人反应时间已知）； 相应的 MOT +状态估计模块输出的指标为各距离维度各类别维度下的： 误检率； 漏检率； ID Switch； 定位精度； 速度估计精度； 其中 MOT 主要涉及误检率，漏检率，ID Switch（直接影响状态估计模块）。这些指标的计算方式可以在学术界定义的基础上做进一步改进，比如漏检率，就需要体现出百公里漏报率的性能，所以可以考虑将连续 N 帧漏检的目标才归为漏检，分母可以定义为每多少帧。此外，要在各距离维度各类别维度下进行计算，这就涉及到过滤（filter）策略。对于 FCW 而言，首要关注的是本车前方近距离位置，距离维度上的功能重要程度要突显出来，类别维度也要区别对待，以便算法模块可以重点优化。 2.2.&ensp;自动驾驶中的动态障碍物检测功能 自动驾驶中动态障碍物检测的要求就高了，子模块也较为复杂，指标除了评估功能模块的性能，还需要指导迭代各子模块算法，包括本子模块的迭代比较，以及上下游模块相关指标的对比。 功能需求，我们简单列举几项： 不允许漏检，尽可能不误检； 前向，后向，侧向观测距离分别要达到 x, y, z； 相应的功能指标为： 漏检率； 误检率； 观测距离； 观测精度； 观测时延(delay)； MOT +状态估计模块输出的指标依然在各距离维度各类别维度下： 误检率； 漏检率； ID Switch； 定位精度； 尺寸，朝向，速度估计精度； 状态估计收敛时间； 一系列描述时序稳定性的指标； 与前述 FCW 功能类似，只是多了较多的指标。过滤操作也做的更加细致，我们还可以将目标做重要性等级划分，比如本车道前车多少米内，那指标基本都要达到 99%+；还可以将地面区域做重要性划分（比距离维度更加细致，可以认为是三维层面），周围几米内，那误检率肯定要非常低。除了过滤策略需要仔细设计外，匹配策略也需要进一步思考。如果传感器本身精度就有限，那么匹配策略就要相应放宽。还需注意的是引入过滤策略后，FP与FN计算的细微差别，比如有个过滤条件为去除目标像素面积小于一定阈值的目标集 A，观测值与真值匹配时，如果与 A 中的目标匹配上，那么不应该记为 FP，如果没匹配上 A 中的目标，那么 A 中地目标也不应该被记为 FN。这种类似的情况逻辑要思考清楚。 3.&ensp;Summary 以上设计的出发点是，我们要承认算法的不完美性以及传感器的局限性，在工程领域，一定要首先解决主要矛盾，再打磨细节。本文还对以下内容未作进一步分析（以后有机会再写文细究）： 状态估计时序相关指标，描述估计的时序稳定性，也可以用于 MOT 的评估； 标注与过滤策略的关系，过滤策略往往依赖于标注策略； 各个指标的阈值确定，确定阈值也是产品中一件重要而又系统的事，有时候比指标设计更复杂； [1] Yang B, Huang C, Nevatia R. Learning affinities and dependencies for multi-target tracking using a CRF model[C]//CVPR 2011. IEEE, 2011: 1233-1240.[2] Choi W, Savarese S. Multiple target tracking in world coordinate with single, minimally calibrated camera[C]//European Conference on Computer Vision. Springer, Berlin, Heidelberg, 2010: 553-567.[3] Kasturi, Rangachar, et al. Framework for performance evaluation of face, text, and vehicle detection and tracking in video: Data, metrics, and protocol IEEE transactions on Pattern Analysis and Machine intelligence 31.2 (2008): 319-336.[4] Yamaguchi K, Berg A C, Ortiz L E, et al. Who are you with and where are you going?[C]//CVPR 2011. IEEE, 2011: 1345-1352.[5] Bernardin K, Stiefelhagen R. Evaluating multiple object tracking performance: the CLEAR MOT metrics[J]. Journal on Image and Video Processing, 2008, 2008: 1.[6] Kratz L, Nishino K. Tracking with local spatio-temporal motion patterns in extremely crowded scenes[C]//2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. IEEE, 2010: 693-700.[7] Ristic B, Vo B N, Clark D, et al. A metric for performance evaluation of multi-target tracking algorithms[J]. IEEE Transactions on Signal Processing, 2011, 59(7): 3452-3457.[8] Schuhmacher D, Vo B T, Vo B N. A consistent metric for performance evaluation of multi-object filters[J]. IEEE transactions on signal processing, 2008, 56(8): 3447-3457.[9] Li Y, Huang C, Nevatia R. Learning to associate: Hybridboosted multi-target tracker for crowded scene[C]//2009 IEEE Conference on Computer Vision and Pattern Recognition. IEEE, 2009: 2953-2960.[10] Song B, Jeng T Y, Staudt E, et al. A stochastic graph evolution framework for robust multi-target tracking[C]//European Conference on Computer Vision. Springer, Berlin, Heidelberg, 2010: 605-619.]]></content>
      <categories>
        <category>MOT</category>
      </categories>
      <tags>
        <tag>MOT</tag>
        <tag>tracking</tag>
        <tag>autonomous driving</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOT 评价指标-"Evaluating Multiple Object Tracking Performance, the CLEAR MOT Metrics"]]></title>
    <url>%2F2019%2F06%2F02%2FMOT-%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87-Evaluating-Multiple-Object-Tracking-Performance-the-CLEAR-MOT-Metrics%2F</url>
    <content type="text"><![CDATA[这篇文章介绍了两个综合性指标 MOTA 以及 MOTP 的计算过程，这两个指标有优劣势，但是作为综合性指标至今在学术界仍广泛应用。本文主要介绍其设计思想及计算过程。 一个理想的 MOT 算法，我们期望每一帧： \(\bullet\) 准确检测目标的数量； \(\bullet\) 准确估计每个目标的状态，如位置，朝向，速度等； \(\bullet\) 准确估计每个目标的轨迹，即目标的 ID 不变性；这就要求评价准则： \(\bullet\) 能评估目标定位的精度； \(\bullet\) 能反映目标轨迹的追踪能力，即同一个目标产生唯一的 ID；此外，为了提高评价准则的实用性： \(\bullet\) 参数尽可能少，阈值可调； \(\bullet\) 易于理解，表现方式符合人们的直觉； \(\bullet\) 有较强的通用性，能评估各种跟踪算法； \(\bullet\) 指标个数少，但是能足够反映算法不同维度的性能；假设第 \(t\) 帧，有目标集 \(\{o_1,…,o_n\}\)，跟踪算法的输出(hypotheses)：\(\{h_1,…h_m\}\)。根据上述设计准则，设计评价计算过程： 1. 构建 \(h_j\) 与 \(o_i\) 的最优匹配； 2. 对于每个匹配对，计算位置估计误差； 3. 累加所有匹配对的误差，包括： a. 计算漏检数(FN)； b. 计算误检数(FP)； c. 计算 ID swith 次数，包括两个邻近目标的 ID 交换，以及遮挡后，同一目标的 ID 跳变；由此可得到两大指标： \(\bullet\) tracking precision，目标位置的估计精度； \(\bullet\) tracking accuracy，包括 misses(FN), FP, mismatches(IDs), failures to recover；下面分两块做细节分析，匹配构建 (Establishing Correspondences) 与评价指标 (Metrics)。 匹配构建 算法估计与目标真值的匹配，大致还是基于匹配最近 object-hypothesis 的思想，没匹配上的估计就是 FP，没匹配上的真值就是 FN。但是这中间需要进一步考虑一些问题。 有效匹配 如果算法估计 \(h_j\) 与目标 \(o_i\) 的最近距离 \(dist_{i,j}\) 超过了一定的阈值 \(T\)，那么这个匹配也是不合理的，因 为这个距离误差加入到定位误差中是不合理的，所以只能说这个跟踪的结果不是这个目标。关于距离的度量： \(\bullet\) 区域（框）跟踪器，距离可用两者的重叠区域来度量，\(T\) 可以设为 0； \(\bullet\) 点跟踪器，距离可用两者中心点的欧氏距离来度量，\(T\) 可以根据目标的尺寸来设定； 跟踪一致性 统计目标与算法输出的匹配跳变的次数，也就是目标 ID 的跳变数。文章还提到，当目标有两个有效地匹 配时，选择之前的匹配，即使那个匹配的距离大于另一个匹配，这点当存在两个很近的目标时，可能会有问 题，需要全局来看。 匹配过程 1. 对 \(t\) 帧，考虑 \(M_{t-1}\) 中所有匹配是否还依然有效，包括目标真值及算法输出是否还存在， 如果都存在，那么距离是否超出阈值 \(T\)； 2. 对于剩下的没找到匹配的真值目标，在唯一匹配以及阈值约束下，可采用匹配算法或者贪心算法来求解， 使得距离误差的总和最小（文章的意思是排除了从上一帧继承的已有匹配，当目标密集时，这部分也应该 加入进来优化）。统计当前帧目标真值匹配的跳变数 \(mme_t\)，作为 mismatch errors； 3. 经过之前两步后，找到了所有的匹配，统计匹配个数为 \(c_t\)，计算匹配上的目标真值与算法输出的定位误 差 \(d_t^i\)； 4. 统计没有匹配上的算法输出 (hypotheses) 为 \(fp_t\)，没有匹配上的目标真值为 \(m_t\)，目标真值个数为 \(g_t\)； 5. 每一帧重复步骤１，第一帧没有 mismatch； 评价指标 基于以上的匹配策略，得出两个合理的指标： \(\bullet\) MOTP(multiple object tracking precision)，跟踪定位精度指标：$$MOTP=\frac{\sum_{i,t}d_t^i}{\sum_tc_t}$$ \(\bullet\) MOTA(multiple object tracking accuracy)，综合了漏检率，误检率，以及 ID 跳变率：$$MOTA=1-\frac{\sum_t(m_t+fp_t+mme_t)}{\sum_tg_t}$$]]></content>
      <categories>
        <category>paper reading</category>
      </categories>
      <tags>
        <tag>paper reading</tag>
        <tag>MOT</tag>
        <tag>tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MOT 综述-'Multiple Object Tracking: A Literature Review']]></title>
    <url>%2F2019%2F05%2F28%2FMOT-%E7%BB%BC%E8%BF%B0-Multiple-Object-Tracking-A-Literature-Review%2F</url>
    <content type="text"><![CDATA[之前做 MOT 还是沿着 SOT 的思路，这篇文章对 MOT 有一个很深入且很有框架性的综述，以下对这篇文章做一个提炼，并加入一些自己的想法。 MOT 作为一个中层任务，是一些高层任务的基础，比如行人的 pose estimation，action recognition，behavior analysis，车辆的 state estimation。单目标跟踪(SOT)主要关注 appearance model 以及 motion model 的设计，解决尺度、旋转、光照等影响因素。而 MOT 包含两个任务：目标数量以及目标ID，这就要求 MOT 还需要解决其它问题： frequent occlusions initialization and termination of tracks similar appearance interactions among multiple objects 问题描述 多目标跟踪实际上是多参数估计问题。给定图像序列\(\{I_1,I_2,…,I_t,…\}\)，第\(t\)帧中目标个数为\(M_t\)，第\(t\)帧中所有目标的状态表示为\(S_t=\{s_t^1,s_t^2,…,s_t^{M_t}\}\)，第\(i\)个目标的轨迹表示为\(s_{1:t}^i=\{s_1^i,s_2^i,…,s_t^i\}\)，所有图像中所有目标的状态序列为\(S_{1:t}=\{S_1,S_2,…,S_t\}\)。相应的，所有图像中所有目标观测到的状态序列为\(O_{1:t}=\{O_1,O_2,…,O_t\}\)。多目标跟踪的优化目标是求解最优的各目标状态，即求解一个后验概率问题，$$ \widehat{S} _ {1:t}=\mathop{\arg\max}_{S_{1:t}}P(S_{1:t}|O_{1:t})$$这种形式有两种实现方法： \(\bullet\) probabilistic inference 适合用于 online tracking 任务，Dynamic Model 为 \(P(S_t|S_{t-1})\)，Observation Model 为 \(P(O_t|S_t)\)，两步求解过程： \(\circ\) Predict: \(P(S_t|O_{1:t-1})=\int P(S_t|S_{t-1})dS_{t-1}\) \(\circ\) Update: \(P(S_t|O_{1:t}) \propto P(O_t|S_t)P(S_t|O_{1:t-1})\) \(\bullet\) deterministic optimization 适合用于 offline tracking 任务，直接利用多帧信息进行最优化求解。 分类方法 initialization method 初始化方式分为： Detection-Based Tracking，优势明显，除了只能处理特定的目标类型； Detection-Free Tracking，能处理任何目标类型； processing mode 根据是否使用未来的观测，处理方式可分为： online tracking，适合在线任务，缺点是观测量会比较少； offline tracking，输出结果存在时延，理论上能获得全局最优解； type of output 根据问题求解方式输出是否存在随机性： probabilistic inference，概率性推断； deterministic inference，求解最大后验概率； 自动驾驶等在线任务主要关注 Detection-Based，online tracking。 框架 MOT 主要考虑两个问题： 目标在不同帧之间的相似性度量，即对appearance, motion, interaction, exclusion, occlusion的建模； 恢复出目标的ID，即 inference 过程； Appearance Model Visual Representation 视觉表达即目标的特征表示方式： 1. local features 本质上是点特征，点特征由 corner+descriptor(角点+描述子) 组成。 KLT(good features to track)在 SOT 中应用广泛，用它可以生成短轨迹，估计相机运动位姿，运动聚 类等；Optical Flow也是一种局部特征，在数据关联之前也可用于将检测目标连接到短轨迹中去。 2. region features 在一个块区域内提取特征，根据像素间作差的次数，可分为： \(\bullet\) zero-order, color histogram &amp; raw pixel template \(\bullet\) first-order, HOG &amp; level-set formulation(?) \(\bullet\) up-to-second-order, Region covariance matrix 3. others 其它特征本质上也需要 local 或 region 的方式提取，只是原始信息并不是灰度或彩图。如 depth, probabilistic occupancy map, gait feature. Local features，比如颜色特征，在计算上比较高效，但是对遮挡，旋转比较敏感；Region features 里，HOG 对光照有一定的鲁棒性，但是对遮挡及形变效果较差；Region covariance matrix 更加鲁 棒，但是需要更高的计算量；深度特征也比较有效，但是需要额外的获取深度信息的代价。 Statistical Measuring 有了目标的特征表示方式之后，就可以评价两个观察的目标的相似性。特征表示的线索(cue)可分为： 1. single cue 因为只有一个线索，相似性(similarity)可以直接通过两个向量的距离转换得到。可以将距离指数化，高 斯化。也可以将不相似度转为可能性，用协方差矩阵表示。 2. multiple cues 多线索，即多种特征的融合，能极大提高鲁棒性，融合的策略有： \(\bullet\) Boosting, 选取一系列的特征，用 boost 算法选取表达能力最强的特征； \(\bullet\) Concatenation, 各个特征直接在空间维度上串起来，形成一个 cue 的表达方式； \(\bullet\) Summation, 加权融合各个特征，形成一个 cue 的表达方式； \(\bullet\) Product, 各个特征相乘的方式，比如目标 \(s_0\) 的某个潜在匹配 \(s_1\) 的颜色，形状特征为 \(color\), \(shape\) 的概率为 \(p(color|s_0)\), \(p(shape|s_0)\), 假设特征独立，那么， $$p(s_1|s_0)=p(color, shape|s_0)=p(color|s_0)\cdot p(shape|s_0)$$ \(\bullet\) Cascading, coarse-to-fine 的方式，逐步精细化搜索； Motion Model 运动模型对关联两个 tracklets 比较管用，而 online tracking 任务，对输出的时延要求较高，所以其 中一个 tracklet 可以任务就是当前帧与上一帧形成的轨迹，所以这里很难去计算两个 tracklets 的相似度。 能看到的一个应用点就是，通过 motion model 模型，预测下一时刻目标的位置，作为一个线索项目。以 下讨论的各模型主要是为了度量 tracklets 的相似性，从而做 tracklets 的匹配。 Linear \(\bullet\) Velocity Smoothness. N 帧 M 个目标轨迹: \(C_{dyn}=\sum_{t=1}^{N-2}\sum_{i=1}^{M}\parallel v_i^t-v_i^{t+1}\parallel^2\) \(\bullet\) Position Smoothness. \(G(p^{tail}+v^{tail}\Delta t-p^{head}, \sum_p)\cdot G(p^{head}-v^{head}\Delta t-p^{tail}, \sum_p)\) \(\bullet\) Acceleration Smoothness. Non-linear 运动模型假设是非线性的，相似度计算还是按照以上高斯形式。引为中提到，非线性运动模型并不作 为目标的惩罚因子，因为目标并不需要满足该模型，但是只要有目标满足，就降低惩罚系数。 Interaction Model Social Force Models 1. Individual Force \(\bullet\) fidelity, 目标不会改变它的目的地方向； \(\bullet\) constancy, 目标不会突然改变速度和方向； 2. Group Force \(\bullet\) attraction, 目标间应该尽量靠近； \(\bullet\) repulsion, 目标间也得保留适当的距离； \(\bullet\) coherence, 同一个 group 里面的目标速度应该差不多； Crowd Motion Pattern Models 当一个 group 比较密集的时候，单个目标的运动模型不太显著了，这时候群体的运动模型更加有效， 可以用一些方法来构建群体运动模型。 Exclusion Model Detection-level 同一帧两个检测量不能指向同一个目标。匹配 tracklets 时，可以将这一项作为惩罚项。不过目前的检 测技术都做了 NMS，基本可以消除这种情况。 Trajectory-level 两个轨迹不能非常靠近。对于 online tracking 来说，就是 tracking 结果的两个量不能挨在一起，如 果挨在一起，就说明有问题，比如遮挡，或跟丢。 Occlusion Handling \(\bullet\) Part-to-whole, 将目标分成栅格来处理； \(\bullet\) Hypothesize-and-test, \(\bullet\) Buffer-and-recover, 在遮挡产生前，记录一定量的观测，遮挡后恢复； \(\bullet\) Others Inference Probabilistic Inference 概率法只需要用到当前时刻之前的信息，所以适合用于 online tracking 任务。首先，如果假设一阶马 尔科夫，当前目标的状态之依赖于前一时刻目标的状态，即 dynamic model: $$P(S_t|S_{1:t-1})=P(S_t|S_{t-1})$$. 其次，观测是独立的，即当前目标的观测只由当前目标的状态决定，observation model: $$P(O_{1:t}|S_{1:t})=\prod_{i=1}^t P(O_t|S_t)$$. dynamic model 对应的就是跟踪算法策略，observation model 是状态观测手段，包括检测方法。目标状 态估计的迭代过程为： \(\bullet\) predict step, 根据 dynamic model，由目标的上一状态预测当前状态的后验概率分布； \(\bullet\) update step, 根据 observation model，更新当前目标状态的后验概率分布； 状态估计的过程伴随着噪音等因素的影响，常用的概率推断模型有： \(\bullet\) Kalman filter \(\bullet\) Extended Kalman filter \(\bullet\) Particle filter Deterministic Optimization 确定性优化法需要至少一个时间窗口的观测量，所以适合 offline tracking 任务。优化方法有： \(\bullet\) Bipartite graph matching \(\bullet\) Dynamic Programming \(\bullet\) Min-cost max-flow network flow \(\bullet\) Conditional random field \(\bullet\) MWIS(Maximum-weight independent set) 评价方法 评价方法是非常重要的，一方面对算法系统进行调参优化，另一方面比较各个不同算法的优劣。评价方法 (evaluation) 包括评价指标 (metrics) 以及数据集 (datasets)，多类别的数据集主要有： \(\bullet\) MOT Challenge \(\bullet\) KITTI 评价指标可分为： 1. 检测指标 \(\bullet\) 准确性(Accuracy) \(\circ\) Recall &amp; Precision \(\circ\) False Alarme per Frame(FAF) rate, from paper \(\circ\) False Positive Per Image(FPPI), from paper \(\circ\) MODA(Multiple Object Detection Accuracy), 包含了 false positive &amp; miss dets. from paper \(\bullet\) 精确性(Precision) \(\circ\) MODP(Multiple Object Detection Precision), 衡量检测框与真值框的位置对齐程度；from paper 2. 跟踪指标 \(\bullet\) 准确性(Accuracy) \(\circ\) ID switches(IDs), from paper \(\circ\) MOTA(Multiple Object Tracking Accuracy), 包含了FP，FN，mismatch；from paper \(\bullet\) 精确性(Precision) \(\circ\) MOTP(Multiple Object Tracking Precision), from paper \(\circ\) TDE(Tracking Distance Error), from paper \(\circ\) OSPA(optimal subpattern assignment), from paper \(\bullet\) 完整性(Completeness) \(\circ\) MT, the numbers of Mostly Tracked, from paper \(\circ\) PT, the numbers of Partly Tracked \(\circ\) ML, the numbers of Mostly Lost \(\circ\) FM, the numbers of Fragmentation \(\bullet\) 鲁棒性(Robustness) \(\circ\) RS(Recover from Short-term occlusion), from paper \(\circ\) RL(Recover from Long-term occlusion) 评价指标汇总： 总结 还存在的问题 MOT 算法模块较多，参数也较复杂，但是最依赖于检测模块的性能，所以算法间比较性能时，需要注意 按模块进行变量控制。 未来研究方向 \(\bullet\) MOT with video adaptation，检测模块式预先训练的，需要在线更新学习； \(\bullet\) MOT under multiple camera: \(\circ\) multiple views，不同视野相同场景信息的记录， \(\circ\) non-overlapping multi-camera，不同视野不同场景的 reidentification； \(\bullet\) Multiple 3D object tracking，能更准确预测位置，大小，更有效处理遮挡； \(\bullet\) MOT with scene understanding，拥挤场景，用场景理解来有效跟踪； \(\bullet\) MOT with deep learning \(\bullet\) MOT with other cv tasks，和其他任务融合，比如目标分割等；]]></content>
      <categories>
        <category>paper reading</category>
      </categories>
      <tags>
        <tag>paper reading</tag>
        <tag>MOT</tag>
        <tag>tracking</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3D Detection Paper List]]></title>
    <url>%2F2019%2F05%2F22%2F3D-Detection-paper-list%2F</url>
    <content type="text"><![CDATA[这篇文章从输入数据类别上进行 3D Detection paper 的归类。 RGBRGB-D(双目，单目+点云)Lidar]]></content>
      <categories>
        <category>paper reading</category>
      </categories>
      <tags>
        <tag>paper reading</tag>
        <tag>3D Detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Study Topic List]]></title>
    <url>%2F2019%2F05%2F20%2Fstudy-topic-list%2F</url>
    <content type="text"><![CDATA[本文罗列了相关领域知识的学习资料。 Detection 2D Detection 入门 amusi Object Detection @handong Object Detection and Classification using R-CNNs Paper with Code 3D Detection Paper with Code KITTI Leaderboard Tracking Single Object Tracking Paper with Code Multi Object Tracking Paper with Code Paper List MOT Challenge 综述：Multiple Object Tracking: A Literature Review 综述：Online object tracking: A benchmark 综述：MOTChallenge 2015: Towards a benchmark for multi-targettracking Computational Photography 2017年秋季的计算摄影学课程15-463 CNN ACC SLAM 理论知识 计算机视觉中的数学方法 Multiple View Geometry in Computer Vision Probabilistic Robotics(有中文版) State Estimation for Robotics(有中文版) 视觉SLAM十四讲 综述 [Visual Odometry Part I: Fundamentals] [Visual Odometry Part II: Matching, Robustness, Optimization, Applications] Review of Visual Odometry: Types, Approaches, Challenges, and Applications Visual SLAM algorithms: a Survey from 2010 to 2016 Visual SLAM for Driverless Cars: a Brief Survey Visual Simultaneous Locations and Mapping: a Survey 工具 ROS Opencv Camera Calibration Matlab Camera Calibration Toolbox ROS Wiki Camera Calibration 算法 OpenSLAM 其它资料 计算机视觉life Paper with Code]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F05%2F20%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
