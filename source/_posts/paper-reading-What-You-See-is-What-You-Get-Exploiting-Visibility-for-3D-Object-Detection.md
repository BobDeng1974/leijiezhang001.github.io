---
title: '[paper_reading]-"What You See is What You Get, Exploiting Visibility for 3D Object Detection"'
date: 2020-04-22 09:19:59
tags: ["paper reading", "Deep Learning", "autonomous driving", "Point Cloud", "3D Detection"]
categories: 3D Detection
mathjax: true
---

　　Bird-View 3D Detection 都是将点云离散化到 Voxel，有点的 Voxel 提取区域特征，无点的 Voxel 则置为空。而 LiDAR 的测量特性其实还包含更多的信息，{%post_link Grid-Mapping Grid-Mapping%} 中较详细的阐述了 LiDAR 的测量模型，每个栅格可以标记为三个状态：UNKNOWN，FREE，OCCUPIED。传统的 Bird-View 3D Detection 没有显式得提取 UNKNOW 与 FREE 的信息(即没有提取 Visibility 信息)，而 UNKNOW 与 FREE 对数据增广及检测效果非常重要。
<img src="visibility.png" width="90%" height="90%" title="图 1. Visibility or Freespace from LiDAR">
　　如图 1. 所示，左图是传统的点云表示方式，无法区分红色区域是否有车，而右图则非常容易得区分哪个区域不可能有车，哪个区域可能有车。所以本文<a href="#1" id="1ref"><sup>[1]</sup></a>提出了显式提取点云 UNKNOWN 与 FREE 信息来辅助数据增广与提高目标检测精度的方法。

## 1.&ensp;Framework
<img src="framework.png" width="90%" height="90%" title="图 2. Framework">
　　如图 2. 所示，本文的 3D 检测框架与传统的差不多，是 Anchor-Based 方法，主要不同点是输入网络的特征，即点云栅格化后提取出的特征不一样以及融合时序信息。并且，训练过程中，对数据增广做了精心的设计。
<img src="fusion.png" width="90%" height="90%" title="图 3. Frusion Strategy">
　　如图 3. 所示，点云栅格化后提取的特征不一样是指增加了 Visibility 图层。有两种融合方式，前融合是与点云栅格化后提取的特征作 Concate，然后输入到主干网络；后融合则是二者分别通过主干网络，然后再作 Concate。实验表明前融合效果较好。

### 1.1.&ensp;Object Augmentation
　　传统的数据增广关注在全帧点云的平移，旋转，翻转变换。本文则采用目标级别的数据增广。首先生成目标的点云集合，可以用 CAD 模型，也可以直接扣实际的目标点云(扣出来的点云增广能力有限)；然后将目标点云集合随机得放到全帧点云中。在放置的过程中需要模拟 LiDAR 的测量模型，也就是 Visibility 计算过程，这在第 2. 节中详细描述。实验表面能提升 ~9 个点。

### 1.2.&ensp;Temporal Aggregation
　　时序点云信息的利用可以有以下几种方法：

- 将每帧点云栅格化，然后直接在 Chanel 层作 Concate，之后作 3D 卷积，或者先在 Chanel 维度作 1D 卷积，然后作 2D 卷积；
- 将点云中的点增加相对时间戳属性，然后作整体的栅格化，之后直接作传统的 2D 卷积；

本文采用第二种方法，实验表明能提升 ~8 个点。

## 2.&ensp;Visibility Computing
　　{%post_link Grid-Mapping Grid-Mapping%} 中已经应用了 Raycasting 来计算 Visibility/Free。对于点云中的每一个点，我们不仅能获得该点探测到障碍物的这个信息，还能知道，传感器与该点之间的连线上是 Free 的。这就要求能高效得计算该连线相交 Voxel 的集合。该计算模型也用来修正 Object Augmentation 时的点云。

### 2.1.&ensp;Efficient Voxel traversal
　　对每个点，都需要遍历传感器原点到该点所经过的 Voxel，采用 Fast Voxel Traversal<a href="#2" id="2ref"><sup>[2]</sup></a>方法来进行高效的 Voxel 遍历。

### 2.2.&ensp;Raycasting with Augmented Objects
<img src="augment.png" width="90%" height="90%" title="图 4. Rectify Object Augmentation">
　　如图 4. 所示，本文设计了两种策略来修正物体增广：

- Culling，如果该物体是被遮挡的，那么直接去掉，这样会极大减少增广的物体；
- Drilling，如果该物体是被遮挡的，那么将遮挡物去掉，即置为 Free；

实验表明 Drilling 效果较好，在训练时采用该策略进行物体增广后的点云修正，作 Inference 时就直接计算 Freespace 即可。

### 2.3.&ensp;Online Occupancy Mapping
　　栅格内点云提取特征时融合了时序信息，Visibility 也需要融合时序信息，最直观的方式是将 3D Occupancy Map 进行时间维度的堆叠，获得 4D Map，这样对后续的计算量较大。本文采用 OctoMap<a href="#3" id="3ref"><sup>[3]</sup></a> 计算方式，作贝叶斯滤波，得到时序滤波的 3D Occupancy Map。原理与 {%post_link Grid-Mapping Grid-Mapping%} 一样，只不过这里是 3D 的。

## 3.&ensp;Reference
<a id="1" href="#1ref">[1]</a> Hu, Peiyun, et al. "What You See is What You Get: Exploiting Visibility for 3D Object Detection." arXiv preprint arXiv:1912.04986 (2019).  
<a id="2" href="#2ref">[2]</a> Amanatides, John, and Andrew Woo. "A fast voxel traversal algorithm for ray tracing." Eurographics. Vol. 87. No. 3. 1987.  
<a id="3" href="#3ref">[3]</a> Hornung, Armin, et al. "OctoMap: An efficient probabilistic 3D mapping framework based on octrees." Autonomous robots 34.3 (2013): 189-206.
